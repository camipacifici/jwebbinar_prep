{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a0cc965",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "# NIRSpec MOS pipeline processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4f60f7",
   "metadata": {},
   "source": [
    "**Author**: James Muzerolle adapted by Cami Pacifici\n",
    "\n",
    "Plotting function originally developed by Bryan Hilbert\n",
    "\n",
    "**Latest Update**: 28 October 2021 by James, 8 August 2022 by Cami."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbd4add",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Introduction](#intro)\n",
    "    * [Overview](#overview)\n",
    "* [Imports](#imports)\n",
    "* [Convenience functions](#func)\n",
    "* [Pipeline processing flag](#flag)\n",
    "* [Input simulations](#inputs)\n",
    "* [Association files and metadata](#associations)\n",
    "* [Run the calwebb_spec2 pipeline](#runspec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eb5dc4",
   "metadata": {},
   "source": [
    "## Introduction <a id='intro'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e6e77d",
   "metadata": {},
   "source": [
    "In this notebook, we will explore the stage 1 and 2 pipelines for NIRSpec MOS data. Here, we will focus on the mechanics of processing real data, including how to use associations for exposure specification and multi-exposure combination, the role of metadata, and what the primary data products at each stage look like. We will also see examples of how to interact and work with data models and metadata.\n",
    "\n",
    "We are using pipeline version 1.7.+ for all data processing in this notebook. Most of the processing runs shown here use the default reference files from the Calibration Reference Data System (CRDS). Please note that pipeline software development is a continuous process, so results in some cases may be slightly different if using a different version. There are also a few known issues with some of the pipeline steps in this build that are expected to be fixed in the near future, though these do not significantly effect the products you will see here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab1a43a",
   "metadata": {},
   "source": [
    "## Imports <a id='imports'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf18c69",
   "metadata": {},
   "source": [
    "Import packages necessary for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d45c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify the path to a directory on your machine\n",
    "import os\n",
    "os.environ[\"CRDS_PATH\"] = \"/path/to/my/crds/folder\" # set appropriate path\n",
    "os.environ[\"CRDS_SERVER_URL\"] = \"https://jwst-crds.stsci.edu\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "\n",
    "import zipfile\n",
    "import urllib.request\n",
    "\n",
    "import json\n",
    "\n",
    "from shutil import copyfile\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.utils.data import download_file\n",
    "import astropy.units as u\n",
    "from astropy import wcs\n",
    "from astropy.wcs import WCS\n",
    "from astropy.visualization import ImageNormalize, ManualInterval, LogStretch, LinearStretch, AsinhStretch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39940c7b",
   "metadata": {},
   "source": [
    "Set up matplotlib for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f52309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Use this version for non-interactive plots (easier scrolling of the notebook)\n",
    "%matplotlib inline\n",
    "\n",
    "# Use this version (outside of Jupyter Lab) if you want interactive plots\n",
    "#%matplotlib notebook\n",
    "\n",
    "# These gymnastics are needed to make the sizes of the figures\n",
    "# be the same in both the inline and notebook versions\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches': None}\n",
    "\n",
    "mpl.rcParams['savefig.dpi'] = 80\n",
    "mpl.rcParams['figure.dpi'] = 80\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2bb9f0",
   "metadata": {},
   "source": [
    "Import JWST pipeline modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63872971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The calwebb_detector1\n",
    "from jwst.pipeline import Detector1Pipeline\n",
    "\n",
    "# The calwebb_spec and spec3 pipelines\n",
    "from jwst.pipeline import Spec2Pipeline\n",
    "from jwst.pipeline import Spec3Pipeline\n",
    "\n",
    "# individual steps\n",
    "from jwst.assign_wcs import AssignWcsStep\n",
    "from jwst.assign_wcs import nirspec\n",
    "from jwst.background import BackgroundStep\n",
    "from jwst.imprint import ImprintStep\n",
    "from jwst.msaflagopen import MSAFlagOpenStep\n",
    "from jwst.extract_2d import Extract2dStep\n",
    "from jwst.srctype import SourceTypeStep\n",
    "from jwst.wavecorr import WavecorrStep\n",
    "from jwst.flatfield import FlatFieldStep\n",
    "from jwst.pathloss import PathLossStep\n",
    "from jwst.photom import PhotomStep\n",
    "from jwst.cube_build import CubeBuildStep\n",
    "from jwst.extract_1d import Extract1dStep\n",
    "from jwst.combine_1d import Combine1dStep\n",
    "\n",
    "# data models\n",
    "from jwst import datamodels\n",
    "\n",
    "# associations\n",
    "from jwst.associations import asn_from_list\n",
    "from jwst.associations.lib.rules_level3_base import DMS_Level3_Base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170a090f",
   "metadata": {},
   "source": [
    "## Define convenience functions and parameters <a id='func'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470200ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All files created by the steps in this notebook have been pre-computed and cached on Box\n",
    "\n",
    "# first specify a desired local directory in which to place the downloaded data, as well as any offline processing you choose to run\n",
    "output_dir = 'nirspec_files/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "ziplink = 'https://stsci.box.com/shared/static/hydkpkl2ki8c9m6g62abzsog4dao0y3j.zip'\n",
    "zipfilename = 'nirspec_mos_inflight.zip'\n",
    "if not os.path.isfile(os.path.join(output_dir, zipfilename)):\n",
    "    print('Downloading {}...'.format(zipfilename))\n",
    "    demo_file = download_file(ziplink, cache=True)\n",
    "    # Make a symbolic link using a local name for convenience\n",
    "    os.symlink(demo_file, os.path.join(output_dir, zipfilename))\n",
    "else:\n",
    "    print('{} already exists, skipping download...'.format(zipfilename))\n",
    "\n",
    "# unzip\n",
    "zf = zipfile.ZipFile(output_dir+zipfilename, 'r')\n",
    "print(output_dir)\n",
    "zf.extractall(output_dir)\n",
    "\n",
    "os.system('mv '+output_dir+'nirspec_mos_inflight/* '+output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc8efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(data_2d, vmin, vmax, xsize=19, ysize=10, title=None, aspect=1, scale='log', units='MJy/sr'):\n",
    "    \"\"\"Function to generate a 2D, log-scaled image of the data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_2d : numpy.ndarray\n",
    "        2D image to be displayed\n",
    "        \n",
    "    vmin : float\n",
    "        Minimum signal value to use for scaling\n",
    "        \n",
    "    vmax : float\n",
    "        Maximum signal value to use for scaling\n",
    "        \n",
    "    title : str\n",
    "        String to use for the plot title\n",
    "        \n",
    "    scale : str\n",
    "        Specify scaling of the image. Can be 'log' or 'linear'\n",
    "        \n",
    "    units : str\n",
    "        Units of the data. Used for the annotation in the\n",
    "        color bar\n",
    "    \"\"\"\n",
    "    if scale == 'log':\n",
    "        norm = ImageNormalize(data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                              stretch=LogStretch())\n",
    "    elif scale == 'linear':\n",
    "        norm = ImageNormalize(data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                              stretch=LinearStretch())\n",
    "    elif scale == 'Asinh':\n",
    "        norm = ImageNormalize(data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                              stretch=AsinhStretch())\n",
    "    fig = plt.figure(figsize=(xsize, ysize))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    im = ax.imshow(data_2d, origin='lower', norm=norm, aspect=aspect, cmap='gist_earth')\n",
    "\n",
    "    if (units != 'none'):\n",
    "        fig.colorbar(im, label=units)\n",
    "    plt.xlabel('Pixel column')\n",
    "    plt.ylabel('Pixel row')\n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac500fc0",
   "metadata": {},
   "source": [
    "## Pipeline processing flag <a id='flag'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02552e8c",
   "metadata": {},
   "source": [
    "The pipeline and individual steps take too long to run in real time for this demo, so all products shown here have been pre-computed, and the actual pipeline calls will be skipped. Change the following flag to True if you want to run everything offline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f237b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "runflag = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08ce68d",
   "metadata": {},
   "source": [
    "## Input simulations or data <a id='inputs'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10b7a40",
   "metadata": {},
   "source": [
    "## Detector1\n",
    "\n",
    "Update the paths to the correct path on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9117e250",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncalfile1 = './nirspec_files/nirspec_mos_inflight/jw02736007001_03101_00002_nrs1_uncal.fits'\n",
    "uncalfile2 = './nirspec_files/nirspec_mos_inflight/jw02736007001_03101_00002_nrs2_uncal.fits'\n",
    "\n",
    "detector1 = Detector1Pipeline()\n",
    "detector1.save_results = True\n",
    "detector1.output_dir = output_dir\n",
    "result = detector1(uncalfile1)\n",
    "\n",
    "detector1 = Detector1Pipeline()\n",
    "detector1.save_results = True\n",
    "detector1.output_dir = output_dir\n",
    "result = detector1(uncalfile2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185481c6",
   "metadata": {},
   "source": [
    "First, let's take a look at a few of the level 2a images to get familiarized with the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a03990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data model of dither position 1:\n",
    "ratefile1 = output_dir+'jw02736007001_03101_00002_nrs1_rate.fits' # for the NRS1 detector\n",
    "dither1 = datamodels.open(ratefile1)\n",
    "ratefile2 = output_dir+'jw02736007001_03101_00002_nrs2_rate.fits' # for the NRS2 detector\n",
    "dither2 = datamodels.open(ratefile2)\n",
    "\n",
    "# get the pixel data (the SCI extension of the fits file)\n",
    "ratesci1 = dither1.data\n",
    "ratesci2 = dither2.data\n",
    "\n",
    "# display the images\n",
    "show_image(ratesci1, 0, 1., xsize=19, ysize=19, units='DN/s', title='NRS1')\n",
    "show_image(ratesci2, 0, 1., xsize=19, ysize=19, units='DN/s', title='NRS2')\n",
    "\n",
    "# zoom in to show details of one slitlet\n",
    "show_image(ratesci1[1550:1650, 850:1050], 0, 0.1, xsize=19, ysize=15, units='none', scale='Asinh', title='zoom of NRS1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b701e4cf",
   "metadata": {},
   "source": [
    "## Association files and metadata <a id='associations'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371edc36",
   "metadata": {},
   "source": [
    "In this example, we use no background. Background exposures can be found in observations jw02736007001_03101_00003 and jw02736007001_03101_00004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b45229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the contents of one of the association files\n",
    "asn_file = output_dir+\"jw02736-o007_20220712t161855_spec2_011_asn.json\"\n",
    "with open(asn_file) as f_obj:\n",
    "    asn_data = json.load(f_obj)\n",
    "asn_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d237f24c",
   "metadata": {},
   "source": [
    "One unique aspect of MOS data processing is that it requires additional metadata, such as shutter locations and source positions. The pipeline gets this information from an MSA \"metafile\" that is automatically generated, along with the raw \"level 1b\" files, using metadata taken from the PPSDB. The metadata is originally populated when the observation is created with the MSA planning tool in APT. The metafile is a fits file containing two binary fits tables, one with MSA shutter information for each slitlet and nod, and the other with various details about each source observed.  Let's take a look at the metafile for this simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90404df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the MSA metafile\n",
    "metafile = output_dir+'jw02736007001_01_msa.fits'\n",
    "hdul = fits.open(metafile)\n",
    "hdul.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c958f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns of the \"SHUTTER INFO\" table\n",
    "hdul['SHUTTER_INFO'].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6432be8f",
   "metadata": {},
   "source": [
    "In the \"SHUTTER_INFO\" table, the number of rows per slitlet is N_s x N_n, where N_s is the number of open shutters in each slitlet and N_n is the number of nods. In this case, N_s = 3 and N_n = 3, so there are 9 rows per slitlet. These are needed by the pipeline to determine which slitlet shutter contains the source in each nodded exposure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4910466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print table entries for the first two slitlets\n",
    "print(hdul['SHUTTER_INFO'].data[:18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf31faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns of the \"SOURCE_INFO\" table\n",
    "hdul['SOURCE_INFO'].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b580df75",
   "metadata": {},
   "source": [
    "The SOURCE_INFO table contains one row per source that was observed with an MSA configuration. The most important information here are the source RA & Dec coordinates, and the stellarity parameter, which is used to determine whether the source should be processed as point or extended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b3836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print table entries for the first 10 sources\n",
    "print(hdul['SOURCE_INFO'].data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0a6987",
   "metadata": {},
   "source": [
    "## Run the spec2 pipeline <a id='runspec2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d218ae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the calwebb_spec2 pipeline using an association file as input\n",
    "\n",
    "if runflag:\n",
    "    spec2 = Spec2Pipeline()\n",
    "    spec2.save_results = True\n",
    "    spec2.output_dir = output_dir\n",
    "    result = spec2(asn_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f6b45e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# take a look at the results - open the level 2b files\n",
    "\n",
    "callist = [f for f in glob.glob(output_dir+\"jw02736007001_03101_00002_nrs1_cal.fits\")]\n",
    "callist.sort()\n",
    "for calfile in callist:\n",
    "    print(calfile)\n",
    "    cal = datamodels.open(calfile) # this contains the calibrated unrectified 2D spectra\n",
    "    root = calfile[:-9]\n",
    "    s2d = datamodels.open(root+'_s2d.fits')  # this contains the calibrated *rectified* 2D spectra\n",
    "    x1d = datamodels.open(root+'_x1d.fits')  # this contains the aperture-extracted 1D spectra\n",
    "    \n",
    "    for i, slit in enumerate(cal.slits):\n",
    "\n",
    "        #if (slit.name == '31'):  # change this, or comment out, to see other slits\n",
    "            print(slit.name)\n",
    "        \n",
    "            calsci = slit.data  # contains the pixel data from the cal file (SCI extension)\n",
    "            s2dsci = s2d.slits[i].data  # contains the pixel data from the s2d file\n",
    "    \n",
    "            # determine the wavelength scale of the s2d data for plotting purposes\n",
    "            # get the data model WCS object\n",
    "            wcsobj = s2d.slits[i].meta.wcs\n",
    "            y, x = np.mgrid[:s2dsci.shape[0], : s2dsci.shape[1]]  # grid of pixel x,y indices\n",
    "            det2sky = wcsobj.get_transform('detector', 'world')  # the coordinate transform from detector space (pixels) to sky (RA, DEC in degrees)\n",
    "            ra, dec, s2dwave = det2sky(x, y)  # RA, Dec, wavelength (microns) for each pixel\n",
    "            s2dwaves = s2dwave[0, :]  # only need a single row of values since this is the rectified spectrum\n",
    "            xtint = np.arange(100, s2dsci.shape[1], 100)\n",
    "            xtlab = np.round(s2dwaves[xtint], 2)  # wavelength labels for the x-axis\n",
    "        \n",
    "            # get wavelength & flux from the x1d data model\n",
    "            x1dwave = x1d.spec[i].spec_table.WAVELENGTH\n",
    "            x1dflux = x1d.spec[i].spec_table.FLUX\n",
    "  \n",
    "            # plot the unrectified calibrated 2D spectrum\n",
    "            show_image(calsci, -0.01, 0.01, aspect=5., scale='linear', units='MJy')\n",
    "        \n",
    "            # plot the rectified 2D spectrum\n",
    "            show_image(s2dsci, -0.01, 0.01, aspect=5., scale='linear', units='MJy')\n",
    "            plt.xticks(xtint, xtlab)\n",
    "            plt.xlabel('wavelength (microns)')\n",
    "        \n",
    "            # plot the 1D extracted spectrum\n",
    "            fig = plt.figure(figsize=(19, 8))\n",
    "            plt.plot(x1dwave, x1dflux)\n",
    "            plt.xlabel('wavelength (microns)')\n",
    "            plt.ylabel('flux (Jy)')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cfcac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
